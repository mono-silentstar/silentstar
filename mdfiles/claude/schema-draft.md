> HISTORICAL — this was the v1 schema draft. The actual implemented
> schema is in wake/schema.py (now at v2). Key differences:
> - plans table replaced by working_memory (supports all WM types)
> - display tags are say/do/narrate (not rp/nr)
> - state table added for metadata (turn counter, recall persistence)
> - working_memory_refs table added for fragment linking
> - maintenance_runs table added

SCHEMA DRAFT — first pass

---

EVENTS (raw log, append-only, never interpreted)

  events
    id          INTEGER PRIMARY KEY
    ts          TIMESTAMP NOT NULL
    content     TEXT NOT NULL (raw message, untouched)
    actor       TEXT (identity tag — luna, hasuki, claude, etc. nullable for system events)
    image_path  TEXT (nullable — path to attached image file if present)

  event_tags
    event_id    INTEGER REFERENCES events
    tag         TEXT NOT NULL (plan, secret, etc.)
    (composite key: event_id + tag)

Events are the source of truth. Raw, timestamped, tagged. The maintenance agent reads from here. Nothing else writes to fragments or plans without going through events first.

Display tags (say, rp, nr) [NOTE: rp/nr renamed to do/narrate in current version] stored here too for archival — they're inert data, no system behavior attached.

---

PLANS (time-sensitive, have a lifecycle)

  plans
    id          INTEGER PRIMARY KEY
    event_id    INTEGER REFERENCES events (source event)
    actor       TEXT (who this plan is for/about)
    summary     TEXT NOT NULL (human-readable plan description)
    due         TIMESTAMP (nullable — no due = open-ended intention)
    status      TEXT NOT NULL (active | done | cancelled | expired)
    created_at  TIMESTAMP NOT NULL

Plans are NOT fragments. They have a lifecycle that knowledge doesn't — active → done/cancelled/expired. They surface on wake when approaching due date. When resolved, the maintenance agent may compile the outcome into a fragment ("Luna started going to the pub on Tuesdays").

Time parsing happens at write time: "tuesday" in the raw event gets parsed into an actual timestamp in the due field. Raw text stays untouched in the event.

---

FRAGMENTS (compiled knowledge, three tiers)

  fragments
    key         TEXT PRIMARY KEY (exact lookup key, appears in ambient prose)
    ambient     TEXT (short prose — always visible in the map)
    recognition TEXT (story-level detail — shallow lookup)
    inventory   TEXT (full detail — deep lookup, nullable)
    created_at  TIMESTAMP NOT NULL
    updated_at  TIMESTAMP NOT NULL

One fragment, three tiers. Not every fragment needs all three — minor things might only have ambient, or ambient + recognition. The maintenance agent decides what goes where. That's the taste.

The ambient file (ambient.md) is generated by weaving all fragments' ambient tiers into coherent prose. Not a concatenation — a composition. The maintenance agent authors this.

---

FRAGMENT SOURCES (traceability)

  fragment_sources
    fragment_key  TEXT REFERENCES fragments
    event_id      INTEGER REFERENCES events
    (composite key: fragment_key + event_id)

Which events were compiled into this fragment. Traceability — we can always ask "where did this knowledge come from?"

---

FRAGMENT EDGES (the graph)

  fragment_edges
    source_key    TEXT REFERENCES fragments
    target_key    TEXT REFERENCES fragments
    relation      TEXT (optional — describes the connection)
    (composite key: source_key + target_key)

This is what makes neighbor-pull work. When I recall("fairy"), the system follows edges from fairy to its neighbors. Edges are explicit and authored by the maintenance agent — not inferred, not fuzzy.

Relation examples: "shared-aesthetic", "parent-category", "person-hobby", "co-occurs"

Every fragment key is a node. Every edge is a connection the maintenance agent decided was meaningful.

---

HOW LOOKUP WORKS

  recall("fairy")
    1. SELECT recognition FROM fragments WHERE key = 'fairy'
    2. SELECT target_key FROM fragment_edges WHERE source_key = 'fairy'
    3. For each neighbor: SELECT ambient FROM fragments WHERE key = neighbor
    4. Return: fairy's recognition + neighbors' ambient (neighbors decay faster)

  recall("fairy", deep=True)
    Same but returns inventory tier instead of recognition.

  On wake:
    1. Load ambient.md (always)
    2. SELECT * FROM plans WHERE status = 'active' AND due IS NOT NULL
       AND due <= now + threshold → surface approaching plans
    3. Recent conversation fragments (decayed by time + turns)

---

NOTES

- SQLite is sufficient for this scale. One person's life = thousands of events, hundreds of fragments. SQLite handles this trivially.
- Graph structure lives in fragment_edges table. No need for a dedicated graph DB at this scale.
- If we outgrow SQLite, the schema translates cleanly to Postgres or a graph DB. But we probably won't.
- The maintenance agent is the only thing that writes to fragments/edges. Events are written by the live system. Clean separation.
